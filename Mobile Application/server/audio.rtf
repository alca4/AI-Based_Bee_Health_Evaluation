{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red157\green0\blue210;\red245\green245\blue245;\red0\green0\blue0;
\red15\green112\blue1;\red144\green1\blue18;\red0\green0\blue255;\red101\green76\blue29;\red0\green0\blue109;
\red19\green85\blue52;}
{\*\expandedcolortbl;;\cssrgb\c68627\c0\c85882;\cssrgb\c96863\c96863\c96863;\cssrgb\c0\c0\c0;
\cssrgb\c0\c50196\c0;\cssrgb\c63922\c8235\c8235;\cssrgb\c0\c0\c100000;\cssrgb\c47451\c36863\c14902;\cssrgb\c0\c6275\c50196;
\cssrgb\c6667\c40000\c26667;}
\margl1440\margr1440\vieww19840\viewh14100\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 import\cf0 \strokec4  librosa\cb1 \
\cf2 \cb3 \strokec2 import\cf0 \strokec4  numpy \cf2 \strokec2 as\cf0 \strokec4  np\cb1 \
\cf2 \cb3 \strokec2 from\cf0 \strokec4  keras.models \cf2 \strokec2 import\cf0 \strokec4  load_model\cb1 \
\cf2 \cb3 \strokec2 import\cf0 \strokec4  os\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 # Load your trained model\cf0 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 model = load_model(\cf6 \strokec6 'bee_health_multimodel.h5'\cf0 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 # Path to the audio file\cf0 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 audio_file = \cf6 \strokec6 \'91*.wav'\cf0 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 # Function to extract features (e.g., Mel spectrogram) from the audio file\cf0 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 def\cf0 \strokec4  \cf8 \strokec8 extract_mel_spectrogram\cf0 \strokec4 (\cf9 \strokec9 audio_file\cf0 \strokec4 , \cf9 \strokec9 sr\cf0 \strokec4 =\cf10 \strokec10 22050\cf0 \strokec4 , \cf9 \strokec9 n_mels\cf0 \strokec4 =\cf10 \strokec10 128\cf0 \strokec4 , \cf9 \strokec9 hop_length\cf0 \strokec4 =\cf10 \strokec10 512\cf0 \strokec4 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3     \cf5 \strokec5 # Load the audio file\cf0 \cb1 \strokec4 \
\cb3     audio, sample_rate = librosa.load(audio_file, sr=sr)\cb1 \
\
\cb3     \cf5 \strokec5 # Generate Mel spectrogram\cf0 \cb1 \strokec4 \
\cb3     mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels, hop_length=hop_length)\cb1 \
\
\cb3     \cf5 \strokec5 # Convert the Mel spectrogram to decibel units\cf0 \cb1 \strokec4 \
\cb3     mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\cb1 \
\
\cb3     \cf2 \strokec2 return\cf0 \strokec4  mel_spectrogram_db\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 # Extract Mel spectrogram from the audio file\cf0 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 mel_spectrogram = extract_mel_spectrogram(audio_file)\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 # Resize and flatten the Mel spectrogram to match the model's expected input size\cf0 \cb1 \strokec4 \
\cf5 \cb3 \strokec5 # Assuming the model expects a 4096-dimensional input\cf0 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 mel_spectrogram_resized = np.resize(mel_spectrogram, (\cf10 \strokec10 4096\cf0 \strokec4 ,))\cb1 \
\cb3 mel_spectrogram_resized = mel_spectrogram_resized.reshape(\cf10 \strokec10 1\cf0 \strokec4 , \cf10 \strokec10 4096\cf0 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 # Prepare a dummy image input since the model expects two inputs\cf0 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 dummy_image_input = np.zeros((\cf10 \strokec10 1\cf0 \strokec4 , \cf10 \strokec10 4096\cf0 \strokec4 ))  \cf5 \strokec5 # Match the shape of the image input (1, 4096)\cf0 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 # Make the prediction by passing both the dummy image input and the actual audio input\cf0 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 prediction = model.predict([dummy_image_input, mel_spectrogram_resized])\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 # Define the class labels\cf0 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 classes = [\cf6 \strokec6 'healthy'\cf0 \strokec4 , \cf6 \strokec6 'ant problems'\cf0 \strokec4 , \cf6 \strokec6 'missing queen'\cf0 \strokec4 , \cf6 \strokec6 'pesticide'\cf0 \strokec4 ]\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 # Output the probability for each class label\cf0 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 for\cf0 \strokec4  i, label \cf7 \strokec7 in\cf0 \strokec4  \cf8 \strokec8 enumerate\cf0 \strokec4 (classes):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3     \cf8 \strokec8 print\cf0 \strokec4 (\cf7 \strokec7 f\cf6 \strokec6 "\cf0 \strokec4 \{label\}\cf6 \strokec6 : \cf0 \strokec4 \{prediction[\cf10 \strokec10 0\cf0 \strokec4 ][i]*\cf10 \strokec10 100:.2f\cf0 \strokec4 \}\cf6 \strokec6 %"\cf0 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 # Output the predicted class\cf0 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 predicted_class = np.argmax(prediction)\cb1 \
\pard\pardeftab720\partightenfactor0
\cf8 \cb3 \strokec8 print\cf0 \strokec4 (\cf7 \strokec7 f\cf6 \strokec6 "Predicted bee health condition: \cf0 \strokec4 \{classes[predicted_class]\}\cf6 \strokec6 "\cf0 \strokec4 )\cb1 \
\
}